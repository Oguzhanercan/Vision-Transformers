{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T11:28:48.806795Z","iopub.status.busy":"2022-07-02T11:28:48.80611Z","iopub.status.idle":"2022-07-02T11:29:02.982131Z","shell.execute_reply":"2022-07-02T11:29:02.981013Z","shell.execute_reply.started":"2022-07-02T11:28:48.806702Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import einops\n","import torchvision\n","import torchvision.transforms as transforms\n","import cv2\n","import numpy as np\n","from torchvision import datasets\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import os\n","from pathlib import Path\n","import torch\n","from PIL import Image\n","from tqdm import tqdm\n","from torchmetrics import F1Score"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T11:29:45.969212Z","iopub.status.busy":"2022-07-02T11:29:45.968395Z","iopub.status.idle":"2022-07-02T11:29:45.979427Z","shell.execute_reply":"2022-07-02T11:29:45.978295Z","shell.execute_reply.started":"2022-07-02T11:29:45.969178Z"},"trusted":true},"outputs":[],"source":["class Project(nn.Module):\n","    def __init__(self,N:int,in_channels,embed_size,batch_size):\n","        super().__init__()\n","        self.N = N #patch size\n","        self.batch_size = batch_size \n","        self.embed_size = embed_size # embed size is the size of linearly projected patch of image\n","        self.in_channels = in_channels # channel size of image, 1 for grayscale, 3 for colored image\n","        self.linear1 = nn.Linear(self.in_channels*self.N**2,self.embed_size) # Linear projection layer\n","        self.cls = nn.Parameter(torch.randn(self.batch_size,1,embed_size))\n","        self.position_em = nn.Parameter(torch.randn(self.N**2+1,self.embed_size))\n","    def forward(self,x:torch.Tensor):\n","        out = einops.rearrange(x,\"b c (h px) (w py) ->b (h w) (c px py)\",px =self.N,py =self.N)\n","        out = self.linear1(out)\n","        \n","        out = torch.cat([out,self.cls],dim =1)\n","        out = out+self.position_em\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T11:29:46.359574Z","iopub.status.busy":"2022-07-02T11:29:46.358651Z","iopub.status.idle":"2022-07-02T11:29:46.367481Z","shell.execute_reply":"2022-07-02T11:29:46.366423Z","shell.execute_reply.started":"2022-07-02T11:29:46.359541Z"},"trusted":true},"outputs":[],"source":["class DotProductAttention(nn.Module):\n","    def __init__(self,embed_size):\n","        super().__init__()\n","        self.embed_size = embed_size\n","        self.query = nn.Linear(self.embed_size,self.embed_size)\n","        self.key = nn.Linear(self.embed_size, self.embed_size)\n","        self.value = nn.Linear(self.embed_size,self.embed_size)\n","        self.softmax = nn.Softmax(dim =1)\n","    def forward(self,embed: torch.Tensor):\n","        query = self.query(embed)\n","        key  = einops.rearrange(self.key(embed),\"b n e ->b e n\")\n","        value = self.value(embed)\n","        sdp = torch.matmul(self.softmax(torch.matmul(query,key)/key.size(dim = 2)**(1/2)),value)\n","        return sdp"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T11:29:46.387437Z","iopub.status.busy":"2022-07-02T11:29:46.387157Z","iopub.status.idle":"2022-07-02T11:29:46.394079Z","shell.execute_reply":"2022-07-02T11:29:46.393105Z","shell.execute_reply.started":"2022-07-02T11:29:46.387411Z"},"trusted":true},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self,embed_size,num_heads):\n","        super().__init__()\n","        self.num_heads = num_heads\n","        self.embed_size = embed_size\n","        self.embed_part = int(self.embed_size/self.num_heads)\n","        self.DotProductAttention = DotProductAttention(self.embed_part)\n","        \n","    def forward(self,embed):\n","        \n","        splitted_embed = torch.tensor_split(embed,self.num_heads,dim = 2)\n","        spds = [self.DotProductAttention(i) for i in splitted_embed]\n","        return torch.concat(spds,dim = 2)\n","        \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T11:29:46.541727Z","iopub.status.busy":"2022-07-02T11:29:46.54117Z","iopub.status.idle":"2022-07-02T11:29:46.550148Z","shell.execute_reply":"2022-07-02T11:29:46.548913Z","shell.execute_reply.started":"2022-07-02T11:29:46.541687Z"},"trusted":true},"outputs":[],"source":["class EncoderBlock(nn.Module):\n","    def __init__(self,embed_size,num_heads,N,in_channels,batch_size):\n","        super().__init__()\n","        self.num_heads = num_heads\n","        self.embed_size = embed_size\n","        self.N = N\n","        self.in_channels = in_channels\n","        self.batch_size = batch_size\n","        self.mha = MultiHeadAttention(embed_size,num_heads)\n","        self.Linear = nn.Linear(embed_size,embed_size)\n","        self.layernorm = nn.LayerNorm(self.embed_size)\n","        self.proj = Project(self.N,self.in_channels,self.embed_size,self.batch_size)\n","    def forward(self,embed):\n","        out = self.mha(embed)\n","        out = out + embed\n","        out = self.layernorm(out)\n","        out = self.Linear(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T11:29:46.775842Z","iopub.status.busy":"2022-07-02T11:29:46.77556Z","iopub.status.idle":"2022-07-02T11:29:46.788182Z","shell.execute_reply":"2022-07-02T11:29:46.786843Z","shell.execute_reply.started":"2022-07-02T11:29:46.775816Z"},"trusted":true},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(self,embed_size,num_heads,N,in_channels,batch_size,num_encoders,num_class,device):\n","        super().__init__()\n","        self.device = device\n","        self.num_heads = num_heads\n","        self.embed_size = embed_size\n","        self.N = N\n","        self.in_channels = in_channels\n","        self.batch_size = batch_size\n","        self.num_encoders = num_encoders\n","        self.num_class = num_class\n","        self.proj = Project(self.N,self.in_channels,self.embed_size,self.batch_size)\n","\n","        self.tiny_block = [nn.Sequential(nn.LayerNorm(self.embed_size),EncoderBlock(self.embed_size,self.num_heads,self.N,self.in_channels,self.batch_size)) for i in range(num_encoders)]\n","        self.block_seq = nn.Sequential(*self.tiny_block)\n","        \n","        self.Linear = nn.Linear(self.embed_size,self.num_class)\n","        \n","        self.layernorm = nn.LayerNorm(num_class)\n","\n","        indices = [i for i in range(self.num_class)]\n","        self.indices = torch.tensor(indices)\n","    \n","    def num_of_parameters(self,):\n","\n","        return sum(p.numel() for p in self.parameters())\n","    \n","    def forward(self,img):\n","        out = self.proj(img)\n","        out = self.block_seq(out)\n","        out = self.Linear(torch.squeeze(torch.index_select(out,1,torch.tensor(self.N**2).to(self.device))))\n","        out = self.layernorm(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T11:29:47.006486Z","iopub.status.busy":"2022-07-02T11:29:47.006163Z","iopub.status.idle":"2022-07-02T11:29:47.021571Z","shell.execute_reply":"2022-07-02T11:29:47.020479Z","shell.execute_reply.started":"2022-07-02T11:29:47.006456Z"},"trusted":true},"outputs":[],"source":["class Custom_Dataset():\n","\n","    def __init__(self, directory, mode=\"train\"):\n","        self.path = Path(directory)\n","        Path.ls = lambda x: list(x.iterdir())\n","        try:\n","            files = os.listdir(directory)\n","            print(files)\n","        except:\n","            print(\"wrong path\")\n","        self.x = [torch.tensor(np.transpose(np.array(Image.open(img).resize((144,144))), (2, 0, 1))).type(\n","            torch.FloatTensor) for img in (self.path/files[0]).ls()]\n","        self.x = torch.stack(self.x)/255\n","        self.y = torch.tensor([0]*len((self.path/files[0]).ls()))\n","        for i in range(len(files)-1):\n","            self.x2 = [torch.tensor(np.transpose(np.array(Image.open(img).resize((144,144))), (2, 0, 1))).type(\n","                torch.FloatTensor) for img in (self.path/files[i+1]).ls()]\n","            self.x2 = torch.stack(self.x2)/255\n","            self.x = torch.cat((self.x, self.x2), 0)\n","            self.y = torch.cat((self.y, torch.tensor(\n","                [i+1]*len((self.path/files[i+1]).ls()))))\n","        \n","    def __len__(self):\n","        return len(self.x)\n","    \n","    def __getitem__(self, i):\n","        return self.x[i], self.y[i]\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T11:29:47.309463Z","iopub.status.busy":"2022-07-02T11:29:47.308813Z","iopub.status.idle":"2022-07-02T11:31:55.235139Z","shell.execute_reply":"2022-07-02T11:31:55.234004Z","shell.execute_reply.started":"2022-07-02T11:29:47.309429Z"},"trusted":true},"outputs":[],"source":["dataset = Custom_Dataset(\"../input/good-guysbad-guys-image-data-set/train\") # https://www.kaggle.com/datasets/gpiosenka/good-guysbad-guys-image-data-set"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T11:31:55.238033Z","iopub.status.busy":"2022-07-02T11:31:55.237424Z","iopub.status.idle":"2022-07-02T11:31:55.248634Z","shell.execute_reply":"2022-07-02T11:31:55.24767Z","shell.execute_reply.started":"2022-07-02T11:31:55.237994Z"},"trusted":true},"outputs":[],"source":["def train_val_loader(dataset,batch_size,valid_per,mode):\n","    if mode == \"train\":\n","        indices = torch.randperm(len(dataset))\n","        split = int(np.floor((valid_per)*(len(dataset))))\n","        t_idx, v_idx = indices[:split], indices[split:]\n","        train_sampler = SubsetRandomSampler(t_idx)\n","        val_sampler = SubsetRandomSampler(v_idx)\n","        trainloader = torch.utils.data.DataLoader(\n","            dataset, batch_size=batch_size, num_workers=2, drop_last=True, sampler=train_sampler)\n","        validloader = torch.utils.data.DataLoader(\n","            dataset, batch_size=batch_size, num_workers=2, drop_last=True, sampler=val_sampler)\n","        return trainloader, validloader\n","    elif mode == \"test\":\n","        testloader = torch.utils.data.DataLoader(\n","                dataset, batch_size=abatch_size, num_workers=2, drop_last=True)\n","        return testloader\n","\n","    else:\n","        print(\"Invalid mode\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T11:31:55.250517Z","iopub.status.busy":"2022-07-02T11:31:55.250035Z","iopub.status.idle":"2022-07-02T11:31:55.263319Z","shell.execute_reply":"2022-07-02T11:31:55.262315Z","shell.execute_reply.started":"2022-07-02T11:31:55.25048Z"},"trusted":true},"outputs":[],"source":["train_loader, val_loader = train_val_loader(dataset,batch_size,valid_per,\"train\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T11:38:06.326475Z","iopub.status.busy":"2022-07-02T11:38:06.325892Z","iopub.status.idle":"2022-07-02T11:38:06.334669Z","shell.execute_reply":"2022-07-02T11:38:06.33341Z","shell.execute_reply.started":"2022-07-02T11:38:06.32644Z"},"trusted":true},"outputs":[],"source":["f1 = F1Score(num_classes=2).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T12:43:30.567706Z","iopub.status.busy":"2022-07-02T12:43:30.567344Z","iopub.status.idle":"2022-07-02T12:43:30.582667Z","shell.execute_reply":"2022-07-02T12:43:30.581543Z","shell.execute_reply.started":"2022-07-02T12:43:30.567676Z"},"trusted":true},"outputs":[],"source":["\n","def train(trainloader, validloader, model, optimizer, criterion,epochs,f1,batch_size):\n","    device = \"cuda\"\n","    valid_loss_min = np.Inf\n","    for i in range(epochs):\n","        print(\"Epoch - {} Started\".format(i+1))\n","\n","        train_loss = 0.0\n","        valid_loss = 0.0\n","        train_score = 0.0\n","        val_score = 0.0\n","        model.train()\n","        for data, target in tqdm(trainloader):\n","            data, target = data.to(device), target.to(device)\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = criterion(output, target)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item()*data.size(0)\n","            train_score = train_score +f1(output,target)\n","        model.eval()\n","        for data, target in validloader:\n","            data, target = data.to(device), target.to(device)\n","            with torch.no_grad():\n","                output = model(data)\n","            loss = criterion(output, target)\n","            valid_loss += loss.item()*data.size(0)\n","            val_score = val_score + f1(output,target)\n","        train_loss = train_loss/len(trainloader.sampler)\n","        valid_loss = valid_loss/len(validloader.sampler)\n","        train_score = batch_size*train_score/len(trainloader.sampler)\n","        val_score = batch_size*val_score/len(validloader.sampler)\n","        print(f\"F1 Score for train: {train_score}, F1 Score for validation: {val_score} \")\n","        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","            i+1, train_loss, valid_loss))\n","\n","        if valid_loss <= valid_loss_min:\n","            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","                valid_loss_min,\n","                valid_loss))\n","            \n","            torch.save(model.state_dict(), 'model.pt')\n","            valid_loss_min = valid_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T11:35:20.095088Z","iopub.status.busy":"2022-07-02T11:35:20.094016Z","iopub.status.idle":"2022-07-02T11:35:24.601849Z","shell.execute_reply":"2022-07-02T11:35:24.6008Z","shell.execute_reply.started":"2022-07-02T11:35:20.095051Z"},"trusted":true},"outputs":[],"source":["model = Transformer(embed_size = 512,num_heads = 8,N = 12,in_channels =3,batch_size = 8,num_encoders = 4,num_class = 2,device = \"cuda\").to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T11:35:24.60444Z","iopub.status.busy":"2022-07-02T11:35:24.604054Z","iopub.status.idle":"2022-07-02T11:35:24.610226Z","shell.execute_reply":"2022-07-02T11:35:24.609137Z","shell.execute_reply.started":"2022-07-02T11:35:24.604402Z"},"trusted":true},"outputs":[],"source":["criterion = torch.nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T11:35:24.872609Z","iopub.status.busy":"2022-07-02T11:35:24.872009Z","iopub.status.idle":"2022-07-02T11:35:24.878558Z","shell.execute_reply":"2022-07-02T11:35:24.877388Z","shell.execute_reply.started":"2022-07-02T11:35:24.872568Z"},"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate,betas = (beta1,beta2),weight_decay=weight_decay)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-02T12:47:24.606649Z","iopub.status.busy":"2022-07-02T12:47:24.60618Z","iopub.status.idle":"2022-07-02T14:01:10.012203Z","shell.execute_reply":"2022-07-02T14:01:10.01109Z","shell.execute_reply.started":"2022-07-02T12:47:24.606609Z"},"trusted":true},"outputs":[],"source":["train(train_loader,val_loader,model,optimizer,criterion,100,f1,batch_size)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
