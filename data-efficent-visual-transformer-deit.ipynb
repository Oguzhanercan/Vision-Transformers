{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-07-14T11:07:36.038505Z","iopub.status.busy":"2022-07-14T11:07:36.038086Z","iopub.status.idle":"2022-07-14T11:07:57.021205Z","shell.execute_reply":"2022-07-14T11:07:57.020139Z","shell.execute_reply.started":"2022-07-14T11:07:36.038394Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torch.nn.functional as F\n","!pip install einops\n","import einops\n","import torchvision\n","import torchvision.transforms as transforms\n","import cv2\n","import numpy as np\n","from torchvision import datasets\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import os\n","from pathlib import Path\n","import torch\n","from PIL import Image\n","from tqdm import tqdm\n","from torchmetrics import F1Score\n","import matplotlib.pyplot as plt\n","import copy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["valid_per = 0.20\n","batch_size = 8\n","epochs = 5\n","device = \"cuda\"\n","learning_rate = 0.002\n","beta1 = 0.9\n","beta2 = 0.990\n","weight_decay = 0.3\n","embed_size =768\n","num_heads = 8\n","patch_size = 12\n","in_channels = 3\n","num_encoders = 8\n","num_class = 12"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-07-14T11:11:38.161788Z","iopub.status.busy":"2022-07-14T11:11:38.160927Z","iopub.status.idle":"2022-07-14T11:11:38.172468Z","shell.execute_reply":"2022-07-14T11:11:38.171375Z","shell.execute_reply.started":"2022-07-14T11:11:38.161725Z"},"trusted":true},"outputs":[],"source":["class Project(nn.Module):\n","    def __init__(self,patch_size:int,in_channels:int,embed_size:int,batch_size:int):\n","        super().__init__()\n","        self.patch_size = patch_size\n","        self.batch_size = batch_size \n","        self.embed_size = embed_size # embed size is the size of linearly projected patch of image\n","        self.in_channels = in_channels # channel size of image, 1 for grayscale, 3 for colored image\n","\n","        self.linear = nn.Linear(self.in_channels*self.patch_size**2,self.embed_size)\n","        self.class_token = nn.Parameter(torch.randn(self.batch_size,1,embed_size))\n","        self.distill_token = nn.Parameter(torch.randn(self.batch_size,1,embed_size))\n","        self.position_embed = nn.Parameter(torch.randn(self.patch_size**2+2,self.embed_size))\n","\n","    def forward(self,x:int): # num_batch x in_channel x width x height -> num_bahch x  num_patch x embed_size\n","        out = einops.rearrange(x,\"b c (h px) (w py) -> b (h w) (c px py)\",px = self.patch_size, py = self.patch_size)\n","        out = self.linear(out)\n","        out = torch.cat([out,self.class_token,self.distill_token],dim = 1)\n","        out = out + self.position_embed\n","        return out\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-07-14T11:11:38.477207Z","iopub.status.busy":"2022-07-14T11:11:38.476467Z","iopub.status.idle":"2022-07-14T11:11:38.483067Z","shell.execute_reply":"2022-07-14T11:11:38.482108Z","shell.execute_reply.started":"2022-07-14T11:11:38.477165Z"},"trusted":true},"outputs":[],"source":["class DotProductAttention(nn.Module):\n","    def __init__(self,):\n","        super().__init__()\n","        self.softmax = nn.Softmax(dim = 1)\n","    def forward(self,query,key,value):\n","        \n","        sdp = torch.matmul(self.softmax(torch.matmul(query,key)/key.size(dim = 2)**(1/2)),value)\n","        return sdp"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-07-14T11:11:38.858019Z","iopub.status.busy":"2022-07-14T11:11:38.857246Z","iopub.status.idle":"2022-07-14T11:11:38.870307Z","shell.execute_reply":"2022-07-14T11:11:38.868496Z","shell.execute_reply.started":"2022-07-14T11:11:38.857978Z"},"trusted":true},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self,embed_size,num_heads,dropout = 0.1):\n","        super().__init__()\n","        self.num_heads = num_heads\n","        self.embed_size = embed_size\n","        self.DotProductAttention = DotProductAttention()\n","\n","        self.key = nn.Linear(self.embed_size,self.num_heads* self.embed_size,bias = False)\n","        self.query = nn.Linear(self.embed_size,self.num_heads* self.embed_size,bias = False)\n","        self.value = nn.Linear(self.embed_size,self.num_heads* self.embed_size,bias = False)\n","        \n","        self.linear = nn.Linear(self.num_heads*self.embed_size,embed_size,bias = False)\n","        self.layer_norm = nn.LayerNorm(self.embed_size, eps=1e-6)\n","        self.dropout = nn.Dropout(dropout)\n","    def forward(self,embed):\n","        batch_size = embed.size(0)\n","        query = self.query(embed)\n","        key = einops.rearrange(self.query(embed),\"b n e ->b e n\")\n","        value = self.value(embed)\n","        sdp = self.DotProductAttention(query,key,value)\n","        return self.linear(sdp)\n","        \n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-07-14T11:11:39.212126Z","iopub.status.busy":"2022-07-14T11:11:39.211551Z","iopub.status.idle":"2022-07-14T11:11:39.222071Z","shell.execute_reply":"2022-07-14T11:11:39.220943Z","shell.execute_reply.started":"2022-07-14T11:11:39.212090Z"},"trusted":true},"outputs":[],"source":["class EncoderBlock(nn.Module):\n","    def __init__(self,embed_size,num_heads,dropout = 0.1):\n","        super().__init__()\n","        self.embed_size = embed_size\n","        self.num_heads = num_heads\n","        self.dropout =dropout\n","        self.mha = MultiHeadAttention(768,8)\n","        self.Linear1 = nn.Linear(self.embed_size,self.embed_size*4,bias=False)\n","        self.Linear2 = nn.Linear(self.embed_size*4,self.embed_size,bias = False)\n","        self.gelu = nn.GELU()\n","        self.layer_norm1 = nn.LayerNorm(self.embed_size,eps = 1e-6)\n","        self.layer_norm2 = nn.LayerNorm(self.embed_size,eps = 1e-6)\n","\n","    def forward(self,embed:torch.Tensor):\n","        embed = embed + self.mha(self.layer_norm1(embed))\n","        embed = embed+ self.Linear2(self.gelu(self.Linear1(self.layer_norm2(embed))))\n","        return embed\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-07-14T11:11:39.545589Z","iopub.status.busy":"2022-07-14T11:11:39.545205Z","iopub.status.idle":"2022-07-14T11:11:39.557109Z","shell.execute_reply":"2022-07-14T11:11:39.555998Z","shell.execute_reply.started":"2022-07-14T11:11:39.545554Z"},"trusted":true},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(self,embed_size,num_heads,patch_size,in_channels,batch_size,num_encoders,num_class,device):\n","        super().__init__()\n","        self.device = device\n","        self.num_heads = num_heads\n","        self.embed_size = embed_size\n","        self.patch_size =patch_size\n","        self.in_channels = in_channels\n","        self.batch_size = batch_size\n","        self.num_encoders = num_encoders\n","        self.num_class = num_class\n","        self.proj = Project(self.patch_size,self.in_channels,self.embed_size,self.batch_size)\n","\n","        self.tiny_block = [EncoderBlock(self.embed_size,self.num_heads) for i in range(self.num_encoders)]\n","        self.block_seq = nn.Sequential(*self.tiny_block)\n","        \n","        self.linear1 = nn.Linear(self.embed_size,self.num_class*4)\n","        self.linear2 = nn.Linear(self.num_class*4,self.num_class)\n","    def num_of_parameters(self,):\n","\n","        return sum(p.numel() for p in self.parameters())\n","    \n","    def forward(self,img):\n","        out = self.proj(img)\n","        out = self.block_seq(out)\n","        out = self.linear1(torch.squeeze(torch.index_select(out,1,torch.tensor([self.patch_size**2,self.patch_size**2+1]).to(self.device))))\n","        out = self.linear2(out)\n","\n","        return out"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-07-14T11:11:40.963301Z","iopub.status.busy":"2022-07-14T11:11:40.962315Z","iopub.status.idle":"2022-07-14T11:11:48.293992Z","shell.execute_reply":"2022-07-14T11:11:48.292986Z","shell.execute_reply.started":"2022-07-14T11:11:40.963262Z"},"trusted":true},"outputs":[],"source":["transformer = Transformer(embed_size,num_heads,patch_size,in_channels,batch_size,num_encoders,num_class,device).to(device)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-07-14T11:11:48.296723Z","iopub.status.busy":"2022-07-14T11:11:48.296064Z","iopub.status.idle":"2022-07-14T11:11:48.318464Z","shell.execute_reply":"2022-07-14T11:11:48.317473Z","shell.execute_reply.started":"2022-07-14T11:11:48.296678Z"},"trusted":true},"outputs":[],"source":["class Custom_Dataset():\n","\n","    def __init__(self, directory):\n","        self.path = Path(directory)\n","        Path.ls = lambda x: list(x.iterdir())\n","        try:\n","            files = os.listdir(directory)\n","            print(files)\n","        except:\n","            print(\"wrong path\")\n","        self.x = [torch.tensor(np.transpose(np.array(Image.open(img).resize((144,144)))[:, :, :3], (2, 0, 1))).type(\n","            torch.FloatTensor) for img in (self.path/files[0]).ls()]\n","        self.x = torch.stack(self.x)/255\n","        self.y = torch.tensor([0]*len((self.path/files[0]).ls()))\n","        \n","        for i in range(len(files)-1):\n","            try:\n","                self.x2 = [torch.tensor(np.transpose(np.array(Image.open(img).resize((144,144)))[:, :, :3], (2, 0, 1))).type(\n","                torch.FloatTensor) for img in (self.path/files[i+1]).ls()]\n","            except:\n","                return \n","            self.x2 = torch.stack(self.x2)/255\n","            self.x = torch.cat((self.x, self.x2), 0)\n","            self.y = torch.cat((self.y, torch.tensor(\n","                [i+1]*len((self.path/files[i+1]).ls()))))\n","        \n","    def __len__(self):\n","        return len(self.x)\n","    \n","    def __getitem__(self, i):\n","        return self.x[i], self.y[i]\n","    "]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-07-14T11:11:48.320793Z","iopub.status.busy":"2022-07-14T11:11:48.319981Z","iopub.status.idle":"2022-07-14T11:12:41.988897Z","shell.execute_reply":"2022-07-14T11:12:41.987957Z","shell.execute_reply.started":"2022-07-14T11:11:48.320744Z"},"trusted":true},"outputs":[],"source":["dataset = Custom_Dataset(\"../input/animal-image-classification-dataset/Animal Image Dataset\") # https://www.kaggle.com/datasets/gpiosenka/good-guysbad-guys-image-data-set\n","class_names = {0:\"spider\",1:\"horse\",2:\"butterfly\",3:\"hen\",4:\"elephant\",5:\"sheep\",6:\"dogs\",7:\"cow\",8:\"panda\",9:\"monkey\",10:\"squirrel\",11:\"cats\"}"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-07-14T11:12:41.991468Z","iopub.status.busy":"2022-07-14T11:12:41.990821Z","iopub.status.idle":"2022-07-14T11:12:42.004796Z","shell.execute_reply":"2022-07-14T11:12:42.001009Z","shell.execute_reply.started":"2022-07-14T11:12:41.991393Z"},"trusted":true},"outputs":[],"source":["def data_loaders(dataset,batch_size,train_per,valid_per):\n","\n","    indices = torch.randperm(len(dataset))\n","    split_1 = int(np.floor((train_per)*(len(dataset))))\n","    split_2 = int(np.floor((train_per+valid_per)*(len(dataset))))\n","    t_idx, v_idx,test_idx = indices[:split_1], indices[split_1:split_2],indices[split_2:]\n","    train_sampler = SubsetRandomSampler(t_idx)\n","    val_sampler = SubsetRandomSampler(v_idx)\n","    test_sampler = SubsetRandomSampler(test_idx)\n","    trainloader = torch.utils.data.DataLoader(\n","        dataset, batch_size=batch_size, num_workers=2, drop_last=True, sampler=train_sampler)\n","    validloader = torch.utils.data.DataLoader(\n","        dataset, batch_size=batch_size, num_workers=2, drop_last=True, sampler=val_sampler)\n","    testloader = torch.utils.data.DataLoader(\n","        dataset, batch_size=batch_size, num_workers=2, drop_last=True, sampler=test_sampler)\n","    return trainloader, validloader,testloader\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-13T22:46:33.442025Z","iopub.status.busy":"2022-07-13T22:46:33.441427Z","iopub.status.idle":"2022-07-13T22:46:33.656582Z","shell.execute_reply":"2022-07-13T22:46:33.655363Z","shell.execute_reply.started":"2022-07-13T22:46:33.441985Z"},"trusted":true},"outputs":[],"source":["train_loader,val_loader,test_loader = data_loaders(dataset,8,0.65,0.20)\n","batch = next(iter(train_loader))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-13T22:46:33.658618Z","iopub.status.busy":"2022-07-13T22:46:33.658200Z","iopub.status.idle":"2022-07-13T22:46:33.670343Z","shell.execute_reply":"2022-07-13T22:46:33.669253Z","shell.execute_reply.started":"2022-07-13T22:46:33.658543Z"},"trusted":true},"outputs":[],"source":["def display_examples(class_names, images, labels):\n","    \"\"\"\n","        Display 8 images from the images array with its corresponding labels\n","    \"\"\"\n","    \n","    fig = plt.figure(figsize=(10,6))\n","    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n","    for i in range(8):\n","        plt.subplot(2,4,i+1)\n","        plt.xticks([])\n","        plt.yticks([])\n","        plt.grid(False)\n","        plt.imshow(np.transpose(images[i],(1,2,0)), cmap=plt.cm.binary)\n","        plt.xlabel(class_names[int(labels[i])])\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-13T22:46:33.672942Z","iopub.status.busy":"2022-07-13T22:46:33.672616Z","iopub.status.idle":"2022-07-13T22:46:34.153927Z","shell.execute_reply":"2022-07-13T22:46:34.152033Z","shell.execute_reply.started":"2022-07-13T22:46:33.672902Z"},"trusted":true},"outputs":[],"source":["display_examples(class_names,batch[0][:],batch[1][:])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-13T22:46:34.155408Z","iopub.status.busy":"2022-07-13T22:46:34.155039Z","iopub.status.idle":"2022-07-13T22:46:34.166124Z","shell.execute_reply":"2022-07-13T22:46:34.164801Z","shell.execute_reply.started":"2022-07-13T22:46:34.155370Z"},"trusted":true},"outputs":[],"source":["def test(device,testloader, model, criterion,batch_size):\n","    model.eval()\n","    testloss = 0\n","    correct = 0\n","    i = -1\n","    with torch.no_grad():\n","        for data, target in tqdm(testloader):\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            loss = criterion(output, target)\n","            testloss += loss.item()\n","            #_, predicted = torch.max(output, 1)\n","            _,predicted = torch.max(nn.Softmax()(output),dim = 1)\n","            correct += (predicted == target).sum().item()\n","            i += 1\n","\n","    return correct/(i+1)*batch_size"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-13T22:46:34.171699Z","iopub.status.busy":"2022-07-13T22:46:34.170837Z","iopub.status.idle":"2022-07-13T22:46:34.181859Z","shell.execute_reply":"2022-07-13T22:46:34.180896Z","shell.execute_reply.started":"2022-07-13T22:46:34.171594Z"},"trusted":true},"outputs":[],"source":["def test_transformer(device,testloader, model, criterion,batch_size):\n","    model.eval()\n","    testloss = 0\n","    correct = 0\n","    i = -1\n","    with torch.no_grad():\n","        for data, target in tqdm(testloader):\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            class_embed_out,distill_embed_out = torch.squeeze(torch.index_select(output,1,torch.tensor(0).to(device))).to(device), torch.squeeze(torch.index_select(output,1,torch.tensor(1).to(device))).to(device)\n","            loss = criterion(output, target)\n","            testloss += loss.item()\n","            #_, predicted = torch.max(output, 1)\n","            _,predicted = torch.max(nn.Softmax()(class_embed_out),dim = 1)\n","            correct += (predicted == target).sum().item()\n","            i += 1\n","\n","    return correct/(i+1)*batch_size"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T10:35:25.550298Z","iopub.status.busy":"2022-07-11T10:35:25.549627Z","iopub.status.idle":"2022-07-11T10:35:25.566384Z","shell.execute_reply":"2022-07-11T10:35:25.565313Z","shell.execute_reply.started":"2022-07-11T10:35:25.550261Z"},"trusted":true},"outputs":[],"source":["def train_baseline(trainloader, validloader, model, optimizer, criterion,epochs,f1,batch_size):\n","    device = \"cuda\"\n","    valid_loss_min = np.Inf\n","    model = model.to(device)\n","    for i in range(epochs):\n","        print(\"Epoch - {} Started\".format(i+1))\n","\n","        train_loss = 0.0\n","        valid_loss = 0.0\n","        train_score = 0.0\n","        val_score = 0.0\n","        model.train()\n","        for data, target in tqdm(trainloader):\n","            data, target = data.to(device), target.to(device)\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = criterion(output, target)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item()*data.size(0)\n","            train_score = train_score +f1(output,target)\n","        model.eval()\n","        for data, target in validloader:\n","            data, target = data.to(device), target.to(device)\n","            with torch.no_grad():\n","                output = model(data)\n","            loss = criterion(output, target)\n","            valid_loss += loss.item()*data.size(0)\n","            val_score = val_score + f1(output,target)\n","        train_loss = train_loss/len(trainloader.sampler)\n","        valid_loss = valid_loss/len(validloader.sampler)\n","        train_score = batch_size*train_score/len(trainloader.sampler)\n","        val_score = batch_size*val_score/len(validloader.sampler)\n","        print(f\"F1 Score for train: {train_score}, F1 Score for validation: {val_score} \")\n","        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","            i+1, train_loss, valid_loss))\n","\n","        if valid_loss <= valid_loss_min:\n","            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","                valid_loss_min,\n","                valid_loss))\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            \n","            valid_loss_min = valid_loss\n","    torch.save(best_model_wts, 'model.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T10:35:25.568355Z","iopub.status.busy":"2022-07-11T10:35:25.567903Z","iopub.status.idle":"2022-07-11T10:35:37.526830Z","shell.execute_reply":"2022-07-11T10:35:37.525792Z","shell.execute_reply.started":"2022-07-11T10:35:25.568318Z"},"trusted":true},"outputs":[],"source":["resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True).to(\"cuda\")\n","for param in resnet50.parameters():\n","    param.requires_grad = False\n","resnet50.fc = nn.Linear(2048,12)\n","resnet50 = resnet50.to(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T10:35:37.535367Z","iopub.status.busy":"2022-07-11T10:35:37.531889Z","iopub.status.idle":"2022-07-11T10:35:37.547924Z","shell.execute_reply":"2022-07-11T10:35:37.546982Z","shell.execute_reply.started":"2022-07-11T10:35:37.535328Z"},"trusted":true},"outputs":[],"source":["criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(resnet50.parameters(),lr = learning_rate,betas = (beta1,beta2),weight_decay=weight_decay)\n","f1 = F1Score(num_class).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T10:35:37.557667Z","iopub.status.busy":"2022-07-11T10:35:37.556765Z","iopub.status.idle":"2022-07-11T10:35:59.011982Z","shell.execute_reply":"2022-07-11T10:35:59.010819Z","shell.execute_reply.started":"2022-07-11T10:35:37.557624Z"},"trusted":true},"outputs":[],"source":["train_baseline(train_loader,val_loader,resnet50,optimizer,criterion,1,f1,8)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T10:35:59.014748Z","iopub.status.busy":"2022-07-11T10:35:59.013973Z","iopub.status.idle":"2022-07-11T10:36:01.456478Z","shell.execute_reply":"2022-07-11T10:36:01.453264Z","shell.execute_reply.started":"2022-07-11T10:35:59.014700Z"},"trusted":true},"outputs":[],"source":["test(device,test_loader,resnet50,criterion,batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T10:36:01.462025Z","iopub.status.busy":"2022-07-11T10:36:01.460350Z","iopub.status.idle":"2022-07-11T10:36:01.492233Z","shell.execute_reply":"2022-07-11T10:36:01.490964Z","shell.execute_reply.started":"2022-07-11T10:36:01.461951Z"},"trusted":true},"outputs":[],"source":["def train_transformer(trainloader, validloader, model, optimizer, criterion,epochs,f1,batch_size):\n","    device = \"cuda\"\n","    valid_loss_min = np.Inf\n","    model = model.to(device)\n","    for i in range(epochs):\n","        print(\"Epoch - {} Started\".format(i+1))\n","\n","        train_loss = 0.0\n","        valid_loss = 0.0\n","        train_score = 0.0\n","        val_score = 0.0\n","        model.train()\n","        for data, target in tqdm(trainloader):\n","            data, target = data.to(device), target.to(device)\n","            optimizer.zero_grad()\n","            output = model(data)\n","            class_embed_out,distill_embed_out = torch.squeeze(torch.index_select(output,1,torch.tensor(0).to(device))).to(device), torch.squeeze(torch.index_select(output,1,torch.tensor(1).to(device))).to(device)\n","            loss = criterion(class_embed_out, target)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item()*data.size(0)\n","            train_score = train_score +f1(class_embed_out,target)\n","        model.eval()\n","        for data, target in validloader:\n","            data, target = data.to(device), target.to(device)\n","            with torch.no_grad():\n","                output = model(data)\n","                class_embed_out,distill_embed_out = torch.squeeze(torch.index_select(output,1,torch.tensor(0).to(device))).to(device), torch.squeeze(torch.index_select(output,1,torch.tensor(1).to(device))).to(device)\n","\n","            loss = criterion(class_embed_out, target)\n","            valid_loss += loss.item()*data.size(0)\n","            val_score = val_score + f1(class_embed_out,target)\n","        train_loss = train_loss/len(trainloader.sampler)\n","        valid_loss = valid_loss/len(validloader.sampler)\n","        train_score = batch_size*train_score/len(trainloader.sampler)\n","        val_score = batch_size*val_score/len(validloader.sampler)\n","        print(f\"F1 Score for train: {train_score}, F1 Score for validation: {val_score} \")\n","        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","            i+1, train_loss, valid_loss))\n","\n","        if valid_loss <= valid_loss_min:\n","            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","                valid_loss_min,\n","                valid_loss))\n","            \n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            \n","            valid_loss_min = valid_loss\n","    torch.save(best_model_wts, 'model.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T10:36:01.502140Z","iopub.status.busy":"2022-07-11T10:36:01.498399Z","iopub.status.idle":"2022-07-11T10:38:07.474865Z","shell.execute_reply":"2022-07-11T10:38:07.473435Z","shell.execute_reply.started":"2022-07-11T10:36:01.502100Z"},"trusted":true},"outputs":[],"source":["train_transformer(train_loader,val_loader,transformer,optimizer,criterion,1,f1,8)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T11:32:52.441643Z","iopub.status.busy":"2022-07-11T11:32:52.441277Z","iopub.status.idle":"2022-07-11T11:32:52.811449Z","shell.execute_reply":"2022-07-11T11:32:52.809999Z","shell.execute_reply.started":"2022-07-11T11:32:52.441614Z"},"trusted":true},"outputs":[],"source":["test(device,test_loader,transformer,criterion,batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T10:57:07.255088Z","iopub.status.busy":"2022-07-11T10:57:07.254678Z","iopub.status.idle":"2022-07-11T10:57:07.262378Z","shell.execute_reply":"2022-07-11T10:57:07.260859Z","shell.execute_reply.started":"2022-07-11T10:57:07.255040Z"},"trusted":true},"outputs":[],"source":["def hard_distill_loss(criterion,label,teacher_out,distill_out,class_embed_out,temprature = 1):\n","    distill_embed_probs = F.softmax(distill_out/temprature,dim = 1)\n","    class_embed_probs = F.softmax(class_embed_out/temprature,dim = 1)\n","    teacher_desicion = torch.argmax(teacher_out,dim = 1)\n","    teacher_loss = criterion(distill_embed_probs,teacher_desicion)\n","    gt_loss = criterion(class_embed_probs,label)\n","    hardDistillGlobal = (1/2)*teacher_loss + (1/2)*gt_loss\n","    return hardDistillGlobal"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T11:10:43.568737Z","iopub.status.busy":"2022-07-11T11:10:43.568387Z","iopub.status.idle":"2022-07-11T11:10:43.585358Z","shell.execute_reply":"2022-07-11T11:10:43.584182Z","shell.execute_reply.started":"2022-07-11T11:10:43.568709Z"},"trusted":true},"outputs":[],"source":["def train_distill(trainloader, validloader, model_student,model_teacher, optimizer,criterion,epochs,f1,batch_size):\n","    device = \"cuda\"\n","    valid_loss_min = np.Inf\n","    model_student = model_student.to(device)\n","    model_teacher = model_teacher.to(device)\n","    model_teacher.eval()\n","    for i in range(epochs):\n","        print(\"Epoch - {} Started\".format(i+1))\n","\n","        train_loss = 0.0\n","        valid_loss = 0.0\n","        train_score = 0.0\n","        val_score = 0.0\n","        model_student.train()\n","        for data, target in tqdm(trainloader):\n","            data, target = data.to(device), target.to(device)\n","            optimizer.zero_grad()\n","            student_output = model_student(data)\n","            teacher_output = model_teacher(data)\n","            class_embed_out,distill_embed_out = torch.squeeze(torch.index_select(student_output,1,torch.tensor(0).to(device))).to(device), torch.squeeze(torch.index_select(student_output,1,torch.tensor(1).to(device))).to(device)\n","            loss = hard_distill_loss(criterion,target,teacher_output,distill_embed_out,class_embed_out)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item()*data.size(0)\n","            train_score = train_score +f1(class_embed_out,target)\n","        model_student.eval()\n","        for data, target in validloader:\n","            data, target = data.to(device), target.to(device)\n","            with torch.no_grad():\n","                student_output = model_student(data)\n","                teacher_output = model_teacher(data)\n","            class_embed_out,distill_embed_out = torch.squeeze(torch.index_select(student_output,1,torch.tensor(0).to(device))).to(device), torch.squeeze(torch.index_select(student_output,1,torch.tensor(1).to(device))).to(device)\n","            loss = hard_distill_loss(criterion,target,teacher_output,distill_embed_out,class_embed_out)\n","            valid_loss += loss.item()*data.size(0)\n","            val_score = val_score + f1(class_embed_out,target)\n","        train_loss = train_loss/len(trainloader.sampler)\n","        valid_loss = valid_loss/len(validloader.sampler)\n","        train_score = batch_size*train_score/len(trainloader.sampler)\n","        val_score = batch_size*val_score/len(validloader.sampler)\n","        print(f\"F1 Score for train: {train_score}, F1 Score for validation: {val_score} \")\n","        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","            i+1, train_loss, valid_loss))\n","\n","        if valid_loss <= valid_loss_min:\n","            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","                valid_loss_min,\n","                valid_loss))\n","            best_model_wts = copy.deepcopy(model_student.state_dict())\n","            \n","            valid_loss_min = valid_loss\n","    torch.save(best_model_wts, 'model.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T11:10:50.239934Z","iopub.status.busy":"2022-07-11T11:10:50.239574Z","iopub.status.idle":"2022-07-11T11:32:30.868134Z","shell.execute_reply":"2022-07-11T11:32:30.866483Z","shell.execute_reply.started":"2022-07-11T11:10:50.239903Z"},"trusted":true},"outputs":[],"source":["train_distill(train_loader,val_loader,transformer,resnet50,optimizer,criterion,10,f1,8)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
